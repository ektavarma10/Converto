{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Hand Writing Recognition Using Convolution Neural Network **\n\nThis notebook is the implementation of Machine Learning model to classify writers based on their handwritings . Dataset used is IAM top 50 Dataset (where only 50 handwriting styles are considered).Here is the [Link](https://drive.google.com/drive/folders/1L7VNbUVmzFAq2HtNt31RwW_OosYjubHQ?usp=sharing) for the dataset .\n\nI have built this model using Keras and Tensorflow . It is language independent as we are not considering letters in the classification , but patches of image 113X113 pixels are extracted from data and fit into the model for learning .\n\n**About Model** :\n\nOptimizer : Adam ,\nConvolution Layers : 3 ,\nPooling: Max Pooling ,\nActivation Functions Used : relu , softmax\n\nTotal Layers : 7\n\nThis model gives 81% accuracy on test data for 9 epochs.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"### Imports","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"}},{"cell_type":"code","source":"from __future__ import division\nimport numpy as np\nimport os\nimport glob\n\nfrom random import *\nfrom PIL import Image\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\nfrom keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD, Adam, RMSprop","metadata":{"_uuid":"ff03e0be8b022e42a9f1c880c36bf45c21f04402","execution":{"iopub.status.busy":"2021-07-17T12:18:54.918748Z","iopub.execute_input":"2021-07-17T12:18:54.919037Z","iopub.status.idle":"2021-07-17T12:18:57.812562Z","shell.execute_reply.started":"2021-07-17T12:18:54.918965Z","shell.execute_reply":"2021-07-17T12:18:57.811894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#These are the forms in the dataset for manipulating file names on each column.Create a dictionary with form and writer mapping.\n\n#\nd = {}\nfrom subprocess import check_output\nwith open('../input/iam-handwriting-top50/forms_for_parsing.txt') as f:\n    for line in f:\n        key = line.split(' ')[0]\n        writer = line.split(' ')[1]\n        d[key] = writer\nprint(len(d.keys()))\n","metadata":{"_uuid":"4916eca832ed28a895eca80142ad6c419956a397","execution":{"iopub.status.busy":"2021-07-17T12:19:01.048542Z","iopub.execute_input":"2021-07-17T12:19:01.048826Z","iopub.status.idle":"2021-07-17T12:19:01.082434Z","shell.execute_reply.started":"2021-07-17T12:19:01.048774Z","shell.execute_reply":"2021-07-17T12:19:01.075815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ","metadata":{"_uuid":"b53f31b2cba8e74f0870005093e191daf3fa54c5"}},{"cell_type":"code","source":"tmp = []\ntarget_list = []\n\npath_to_files = os.path.join('../input/iam-handwriting-top50/data_subset/data_subset', '*')\nfor filename in sorted(glob.glob(path_to_files)):\n    #print(filename)\n    tmp.append(filename)\n    image_name = filename.split('/')[-1]\n    file, ext = os.path.splitext(image_name)\n    parts = file.split('-')\n    form = parts[0] + '-' + parts[1]\n    for key in d:\n        if key == form:\n            target_list.append(str(d[form]))\n\nimg_files = np.asarray(tmp)\nimg_targets = np.asarray(target_list)\nprint(img_files.shape)\nprint(img_targets.shape)","metadata":{"_uuid":"43eb1b4e0c76027ca35a89c7f86e5cdfd65dca69","execution":{"iopub.status.busy":"2021-07-17T12:19:04.279125Z","iopub.execute_input":"2021-07-17T12:19:04.279427Z","iopub.status.idle":"2021-07-17T12:19:05.639367Z","shell.execute_reply.started":"2021-07-17T12:19:04.279374Z","shell.execute_reply":"2021-07-17T12:19:05.638522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization of images\nLet's visualize the image data.","metadata":{"_uuid":"b80001a82c05277cbf74b0a92f0dd87f7926cab1"}},{"cell_type":"code","source":"for filename in img_files[:3]:\n    img=mpimg.imread(filename)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap ='gray')","metadata":{"_uuid":"3485223d40941ab326c76d364bc1136a566e7749","execution":{"iopub.status.busy":"2021-07-17T12:19:07.666389Z","iopub.execute_input":"2021-07-17T12:19:07.666676Z","iopub.status.idle":"2021-07-17T12:19:08.081974Z","shell.execute_reply.started":"2021-07-17T12:19:07.666625Z","shell.execute_reply":"2021-07-17T12:19:08.081159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalisation is done using label encoder.\n\nencoder = LabelEncoder()\nencoder.fit(img_targets)\nencoded_Y = encoder.transform(img_targets)\n\nprint(img_files[:5], img_targets[:5], encoded_Y[:5])","metadata":{"_kg_hide-output":false,"_uuid":"efb470a284b84af0b541780aa953396382b9b9a7","execution":{"iopub.status.busy":"2021-07-17T12:19:10.566627Z","iopub.execute_input":"2021-07-17T12:19:10.566948Z","iopub.status.idle":"2021-07-17T12:19:10.57555Z","shell.execute_reply.started":"2021-07-17T12:19:10.566876Z","shell.execute_reply":"2021-07-17T12:19:10.574662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting data into training and validation sets for cross validation with 4:1:1 ratio.\n\n\ntrain_files, rem_files, train_targets, rem_targets = train_test_split(\n        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n\nvalidation_files, test_files, validation_targets, test_targets = train_test_split(\n        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n\nprint(train_files.shape, validation_files.shape, test_files.shape)\nprint(train_targets.shape, validation_targets.shape, test_targets.shape)","metadata":{"_uuid":"cd0cad3ba7235ad7392c9ef22240bf32d33d4d43","execution":{"iopub.status.busy":"2021-07-17T12:19:13.336562Z","iopub.execute_input":"2021-07-17T12:19:13.336835Z","iopub.status.idle":"2021-07-17T12:19:13.351775Z","shell.execute_reply.started":"2021-07-17T12:19:13.336787Z","shell.execute_reply":"2021-07-17T12:19:13.350981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Input to the model\n","metadata":{"_uuid":"4129fb056d957a234bb1d548e37624bb104c6bd3"}},{"cell_type":"code","source":"# Generator function for generating random crops from each sentence\n\n# create generators for randomly cropping 113x113 patches from these images\n\nbatch_size = 8 #16\nnum_classes = 50\n\n# Start with train generator shared in the class and add image augmentations\ndef generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n    num_samples = len(samples)\n    from sklearn.utils import shuffle\n    while 1: # Loop forever so the generator never terminates\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            batch_targets = target_files[offset:offset+batch_size]\n\n            images = []\n            targets = []\n            for i in range(len(batch_samples)):\n                batch_sample = batch_samples[i]\n                batch_target = batch_targets[i]\n                im = Image.open(batch_sample)\n                cur_width = im.size[0]\n                cur_height = im.size[1]\n\n                #print(cur_width, cur_height)\n                height_fac = 113 / cur_height\n\n                new_width = int(cur_width * height_fac)\n                size = new_width, 113\n\n                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n                now_width = imresize.size[0]\n                now_height = imresize.size[1]\n                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n                # Pick random x%\n                pick_num = int(len(avail_x_points)*factor)\n\n                # Now pick\n                random_startx = sample(avail_x_points,  pick_num)\n\n                for start in random_startx:\n                    imcrop = imresize.crop((start, 0, start+113, 113))\n                    images.append(np.asarray(imcrop))\n                    targets.append(batch_target)\n\n            # trim image to only see section with road\n            X_train = np.array(images)\n            y_train = np.array(targets)\n\n            #reshape X_train for feeding in later\n            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n            #convert to float and normalize\n            X_train = X_train.astype('float32')\n            X_train /= 255\n\n            #One hot encode y\n            y_train = to_categorical(y_train, num_classes)\n            yield shuffle(X_train, y_train)","metadata":{"_uuid":"ac174996e85c0cc34466494c032d4ccd66768c69","execution":{"iopub.status.busy":"2021-07-17T12:19:16.517932Z","iopub.execute_input":"2021-07-17T12:19:16.518239Z","iopub.status.idle":"2021-07-17T12:19:16.63993Z","shell.execute_reply.started":"2021-07-17T12:19:16.518171Z","shell.execute_reply":"2021-07-17T12:19:16.639327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For training and testing,  generator function is called with the intent of making train and test generator data.","metadata":{"_uuid":"5d5c49f71f30de1bf86253d44afe5cef879ed1c3"}},{"cell_type":"code","source":"\ntrain_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\nvalidation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\ntest_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)","metadata":{"_uuid":"5e1b1e517cb2db59aaf6ecabdc62b553057b9bdd","execution":{"iopub.status.busy":"2021-07-17T12:19:20.130583Z","iopub.execute_input":"2021-07-17T12:19:20.130862Z","iopub.status.idle":"2021-07-17T12:19:20.137007Z","shell.execute_reply.started":"2021-07-17T12:19:20.130811Z","shell.execute_reply":"2021-07-17T12:19:20.136021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_image(image):\n    import tensorflow as tf\n    return tf.image.resize_images(image,[56,56])\n\n# Function to resize image to 64x64\nrow, col, ch = 113, 113, 1\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n\n# Resise data within the neural network\nmodel.add(Lambda(resize_image))  #resize images to allow for easy computation\n\n# CNN model - Building the model suggested in paper\n\nmodel.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n\nmodel.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n\nmodel.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(512, name='dense1')) \nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, name='dense2'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes,name='output'))\nmodel.add(Activation('softmax'))  #softmax since output is within 50 classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n\n","metadata":{"_uuid":"0eadd72c9a88c06049746d9e8bd1b82931eafa82","execution":{"iopub.status.busy":"2021-07-17T12:19:23.378674Z","iopub.execute_input":"2021-07-17T12:19:23.378947Z","iopub.status.idle":"2021-07-17T12:19:23.62974Z","shell.execute_reply.started":"2021-07-17T12:19:23.378898Z","shell.execute_reply":"2021-07-17T12:19:23.629067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"2648fc5fa1da49052cf982212d42c371e1c8e5c9","execution":{"iopub.status.busy":"2021-07-17T11:56:58.296415Z","iopub.execute_input":"2021-07-17T11:56:58.296687Z","iopub.status.idle":"2021-07-17T11:56:58.308505Z","shell.execute_reply.started":"2021-07-17T11:56:58.296636Z","shell.execute_reply":"2021-07-17T11:56:58.306202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model\n\nLet's take 9 epochs. And the following specifications.","metadata":{"_uuid":"f7a4f8de3dd87584c52e407c774f22d731bd00de"}},{"cell_type":"code","source":"nb_epoch = 9\n\nsamples_per_epoch = 3268\nnb_val_samples = 900\n\nfrom keras.callbacks import ModelCheckpoint\nfilepath=\"check-{epoch:02d}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\ncallbacks_list = [checkpoint]\n\n# #Model fit generator\nhistory_object = model.fit_generator(train_generator, steps_per_epoch = samples_per_epoch/batch_size,\n                                      validation_data=validation_generator,\n                                      validation_steps=nb_val_samples, epochs=nb_epoch, verbose=1, callbacks=callbacks_list)","metadata":{"_uuid":"be9bb7360d3cfc14cdc2a5df5ad47defd05776e3","execution":{"iopub.status.busy":"2021-07-17T14:21:30.641722Z","iopub.execute_input":"2021-07-17T14:21:30.641994Z","iopub.status.idle":"2021-07-17T15:21:33.429245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance Metrics\n\nLet's now test our model for calculating accuracy.","metadata":{"_uuid":"be385264509ecce0061864f0f30f0c95e49e4474"}},{"cell_type":"code","source":"model.load_weights('check-05.hdf5')\nscores = model.evaluate_generator(test_generator,20) \nprint(\"Accuracy = \", scores[1])","metadata":{"_uuid":"921e6244c1ebeb7ccac680503c0987936a42aace","execution":{"iopub.status.busy":"2021-07-17T15:22:44.725735Z","iopub.execute_input":"2021-07-17T15:22:44.726372Z","iopub.status.idle":"2021-07-17T15:22:50.529033Z","shell.execute_reply.started":"2021-07-17T15:22:44.726311Z","shell.execute_reply":"2021-07-17T15:22:50.528362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nfor filename in test_files[:50]:\n     im = Image.open(filename)\n     cur_width = im.size[0]\n     cur_height = im.size[1]\n\n     print(cur_width, cur_height)\n     height_fac = 113 / cur_height\n\n     new_width = int(cur_width * height_fac)\n     size = new_width, 113\n\n     imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n     now_width = imresize.size[0]\n     now_height = imresize.size[1]\n     # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n     avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n     # Pick random x%\n     factor = 0.1\n     pick_num = int(len(avail_x_points)*factor)\n    \n     random_startx = sample(avail_x_points,  pick_num)\n\n     for start in random_startx:\n         imcrop = imresize.crop((start, 0, start+113, 113))\n         images.append(np.asarray(imcrop))\n        \n     X_test = np.array(images)\n    \n     X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n     #convert to float and normalize\n     X_test = X_test.astype('float32')\n     X_test /= 255\n     shuffle(X_test)\n\n     print(X_test.shape)","metadata":{"_uuid":"56f8b903170d0f4d7d496ace5f2954141d5a7e81","execution":{"iopub.status.busy":"2021-07-17T15:23:34.84573Z","iopub.execute_input":"2021-07-17T15:23:34.845996Z","iopub.status.idle":"2021-07-17T15:23:44.246167Z","shell.execute_reply.started":"2021-07-17T15:23:34.845949Z","shell.execute_reply":"2021-07-17T15:23:44.245341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions","metadata":{"_uuid":"c69d84dcc9a5a5df52f441d444bf3d64cbeb3ac5"}},{"cell_type":"code","source":"predictions = model.predict(X_test, verbose =1)\n\nprint(predictions.shape)\npredicted_writer = []\nfor pred in predictions:\n    predicted_writer.append(np.argmax(pred))\n    print(len(predicted_writer))","metadata":{"_uuid":"0458779a20d43667eb416904ddff447b49282124","execution":{"iopub.status.busy":"2021-07-17T15:23:44.247265Z","iopub.execute_input":"2021-07-17T15:23:44.247552Z","iopub.status.idle":"2021-07-17T15:23:45.526244Z","shell.execute_reply.started":"2021-07-17T15:23:44.247507Z","shell.execute_reply":"2021-07-17T15:23:45.525666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights","metadata":{"_uuid":"12f114167ec93e64f4ef3901b544df40ca8aeb67"}},{"cell_type":"code","source":"writer_number = 18\ntotal_images =10\ncounter = 0\nfor i in range(len(predicted_writer)):\n     if predicted_writer[i] == writer_number:\n         image = X_test[i].squeeze()\n         plt.figure(figsize=(2,2))\n         plt.imshow(image, cmap ='gray')\n         print(\"working\")","metadata":{"_uuid":"5da1e6b4bc0c262002a99f590c8f993dcd3780ea","execution":{"iopub.status.busy":"2021-07-17T15:23:53.575917Z","iopub.execute_input":"2021-07-17T15:23:53.576191Z","iopub.status.idle":"2021-07-17T15:23:57.854959Z","shell.execute_reply.started":"2021-07-17T15:23:53.576142Z","shell.execute_reply":"2021-07-17T15:23:57.854169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"References:\nhttps://towardsdatascience.com/handwriting-recognition-using-tensorflow-and-keras-819b36148fe5","metadata":{},"execution_count":null,"outputs":[]}]}